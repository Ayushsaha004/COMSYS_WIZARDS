{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12179333,"sourceType":"datasetVersion","datasetId":7670657},{"sourceId":453315,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":367758,"modelId":388648}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.models import resnet50","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom skimage.transform import resize\nimport imageio.v3 as iio\nimport torch\nimport random\nimport torch.nn as nn\nfrom pathlib import Path\nimport numpy as np","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pretrained Model Path","metadata":{}},{"cell_type":"code","source":"model_path=\"/kaggle/input/hhjhjjh/pytorch/default/1/best_model (2).pth\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test Dataset Path","metadata":{}},{"cell_type":"code","source":"test_dataset_path=\"/kaggle/input/cosmys-face-datast/Comys_Hackathon5/Task_B/val\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Defination","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision.models import resnet50, ResNet50_Weights\n\nclass Mymodel(nn.Module):\n    \n    def __init__(self):\n        super(Mymodel, self).__init__()\n        \n        self.f1 = resnet50(weights=ResNet50_Weights.DEFAULT)\n        self.f1.fc = nn.Identity()  \n        \n        self.f2 = resnet50(weights=ResNet50_Weights.DEFAULT)\n        self.f2.fc = nn.Identity()\n        \n        self.classification = nn.Sequential(\n            nn.Linear(2048, 1),\n            nn.Sigmoid()\n        )\n        \n        self.fc1 = None\n        self.fc2 = None\n        \n\n    def forward(self, x1, x2):\n        \n        fv1 = self.f1(x1)\n        fv2 = self.f2(x2)\n        \n        self.fc1 = fv1\n        self.fc2 = fv2\n        \n        dist = torch.abs(fv1 - fv2)\n        \n        out = self.classification(dist)\n        \n        return out\n        \n\n    def feats(self):\n        return (self.fc1, self.fc2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load the pretrained model","metadata":{}},{"cell_type":"code","source":"model=Mymodel()\nmodel.load_state_dict(torch.load(model_path, map_location=\"cuda\"))\nmodel.to('cuda')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Top 1% Accuracy","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom pathlib import Path\nimport imageio.v3 as iio\nimport torch\nimport numpy as np\nfrom skimage.transform import resize\n\nclass DataPicker(Dataset):\n    def __init__(self, path, size=(224, 224)):\n        self.path = Path(path)\n        self.files = []\n        self.classes = {}\n        self.inx = 0\n        self.size = size\n        \n        for cls in self.path.glob(\"*\"):\n            if not cls.is_dir():\n                continue\n\n            class_name = str(cls.name)\n            self.classes[class_name] = self.inx\n            self.inx += 1\n\n            \n            self.files += [f_path for f_path in cls.glob(\"*\") if f_path.is_file()]\n\n            \n            distortion_folder = cls / \"distortion\"\n            if distortion_folder.exists():\n                self.files += [f_path for f_path in distortion_folder.glob(\"*\") if f_path.is_file()]\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, index):\n        img_path = self.files[index]\n\n        img = iio.imread(img_path)\n\n        \n        if np.issubdtype(img.dtype, np.integer):\n            info = np.iinfo(img.dtype)\n        else:\n            info = np.finfo(img.dtype)\n\n        img = (img - info.min) / (info.max - info.min)\n        img = resize(img, (*self.size, 3), anti_aliasing=True)\n\n        \n        img = torch.from_numpy(img).float().permute(2, 0, 1)\n\n\n        if img_path.parent.name == \"distortion\":\n            class_name = img_path.parent.parent.name\n        else:\n            class_name = img_path.parent.name\n\n        label = self.classes[class_name]\n\n        return img, label\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"datapicker=DataPicker(test_dataset_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(datapicker)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loader=DataLoader(datapicker, batch_size=1, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Testing on Test Dataset","metadata":{}},{"cell_type":"code","source":"m1=model.f1\nm2=model.f2\nclf=model.classification","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model1_feat=[]\nmodel2_feat=[]\ny_true=[]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for img,idx in test_loader:\n    f1=m1(img.to('cuda')).tolist()[0]\n    f2=m2(img.to('cuda')).tolist()[0]\n    model1_feat.append(f1)\n    model2_feat.append(f2)\n    y_true.append(idx[0])\ndf_model1=pd.DataFrame(model1_feat)\ndf_model1['target']=y_true\ndf_model2=pd.DataFrame(model2_feat)\ndf_model2['target']=y_true\ny_target=[int(i) for i in y_true]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_model1['target']=y_target\ndf_model2['target']=y_target","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\n\ndef compute_cross_top1_percent_excluding_self(df_model1, df_model2, clf):\n    \n    clf.eval()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    clf.to(device)\n\n    X1 = df_model1.drop(columns='target').values\n    y1 = df_model1['target'].values\n    X2 = df_model2.drop(columns='target').values\n    y2 = df_model2['target'].values\n\n    n = len(X1)\n    correct = 0\n\n    with torch.no_grad():\n        for i in range(n):\n            f1 = torch.tensor(X1[i], dtype=torch.float32).to(device)  \n            f1_repeated = f1.unsqueeze(0).repeat(n-1, 1)  \n\n            \n            f2_masked = np.delete(X2, i, axis=0)\n            y2_masked = np.delete(y2, i, axis=0)\n\n            f2_tensor = torch.tensor(f2_masked, dtype=torch.float32).to(device) \n            diff = torch.abs(f1_repeated - f2_tensor)  \n\n            \n            scores = clf(diff).squeeze() \n            if scores.dim() == 0:\n                scores = scores.unsqueeze(0)\n\n           \n            top_k = max(1, int(0.01 * (n-1)))\n            \n            top_indices = torch.topk(scores, top_k).indices.cpu().numpy()\n            \n            \n            if any(y2_masked[j] == y1[i] for j in top_indices):\n                correct += 1         \n   \n    return correct / n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"top1_acc = compute_cross_top1_percent_excluding_self(df_model1, df_model2, clf)\nprint(f\"Top 1% Accuracy : {top1_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Macro F1 Score","metadata":{}},{"cell_type":"code","source":"sample_a_class=5\nsample_o_class=6","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def all_pair(l1, l2):\n    return [(i, j) for i in l1 for j in l2]\n\n\ndef all_files(class_paths):\n    imgs = []\n    for cls in class_paths:\n        all_imgs = get_all_imgs(cls)\n        if all_imgs:  \n            imgs.append(random.choice(all_imgs))\n    return imgs\n\n\ndef get_all_imgs(cls_path):\n    imgs = [str(p) for p in cls_path.glob(\"*\") if p.is_file()]\n    distortion_dir = cls_path / \"distortion\"\n    if distortion_dir.exists():\n        imgs += [str(p) for p in distortion_dir.glob(\"*\") if p.is_file()]\n    return imgs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nfrom pathlib import Path\n\n# Main pairing logic\ndata = []\npath = Path(test_dataset_path)\n\nfor cls in path.iterdir():\n    if not cls.is_dir():\n        continue\n\n    # Get all images from current class including distortion\n    class_imgs = get_all_imgs(cls)\n    if len(class_imgs) < max(sample_a_class, sample_o_class):\n        continue  # Skip classes with insufficient images\n\n    # +ve pairs\n    img1_t = random.sample(class_imgs, sample_a_class)\n    img2_t = random.sample(class_imgs, sample_o_class)\n    total_p_pair = all_pair(img1_t, img2_t)\n\n    # -ve pairs\n    other_classes = [c for c in path.iterdir() if c.name != cls.name and c.is_dir()]\n    img1_t = random.sample(class_imgs, sample_a_class)\n    img2_t = all_files(random.sample(other_classes, sample_o_class))\n    total_n_pair = all_pair(img1_t, img2_t)\n\n    # Store pairs\n    for i1, i2 in total_p_pair:\n        data.append([i1, i2, 1])\n    for i1, i2 in total_n_pair:\n        data.append([i1, i2, 0])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test=pd.DataFrame(data,columns=[\"img1\", \"img2\",\"target\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom pathlib import Path\nimport imageio.v3 as iio\nfrom skimage.transform import resize\nimport numpy as np\nimport torch\n\nclass PairPicker(Dataset):\n    def __init__(self, df, size=(224, 224)):\n        self.df = df.sample(frac=1).reset_index(drop=True)  \n        self.size = size\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        img1_path = Path(row[0])  \n        img2_path = Path(row[1])  \n        label = torch.tensor(row[2], dtype=torch.float32)  \n\n        \n        img1 = iio.imread(img1_path)\n        img2 = iio.imread(img2_path)\n\n        \n        img1 = self._normalize_and_resize(img1)\n        img2 = self._normalize_and_resize(img2)\n\n        return img1, img2, label\n\n    def _normalize_and_resize(self, img):\n     \n        if np.issubdtype(img.dtype, np.integer):\n            info = np.iinfo(img.dtype)\n        else:\n            info = np.finfo(img.dtype)\n\n        img = (img - info.min) / (info.max - info.min)\n\n        \n        img = resize(img, (*self.size, 3), anti_aliasing=True)\n        img = torch.from_numpy(img).float().permute(2, 0, 1)\n\n        return img\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport torch\nimport numpy as np\n\ndef evaluate_model(model, val_loader, device='cuda'):\n    model.eval()\n    model.to(device)\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for img1, img2, label in val_loader:\n            img1, img2 = img1.to(device), img2.to(device)\n            label = label.float().to(device)\n\n            output = model(img1, img2).squeeze()\n            pred = (output > 0.5).float()\n\n            all_preds.append([pred.item()])\n            all_labels.append([label.item()])\n\n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n\n    acc = accuracy_score(all_labels, all_preds)\n    print(f\"\\n Accuracy: {acc * 100:.2f}%\")\n\n    print(\"\\n Classification Report:\")\n    print(classification_report(all_labels, all_preds, digits=4))\n\n    cm = confusion_matrix(all_labels, all_preds)\n    print(\"\\n Confusion Matrix:\")\n    print(cm)  \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pairpicker_test=PairPicker(df_test)\ntest_loader=DataLoader(pairpicker_test, batch_size=1, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model, test_loader, device='cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}